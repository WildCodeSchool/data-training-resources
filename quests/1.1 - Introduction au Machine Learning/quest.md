# Introduction au Machine Learning

### Introduction

Le Machine Learning (ou apprentissage automatique) est une branche de l'intelligence artificielle qui permet aux ordinateurs d'**apprendre sans √™tre explicitement programm√©s**.

```alert-infos
**Concept cl√©** :  
Le Machine Learning permet de contourner le paradoxe de Polanyi, qu'Isaac Asimov r√©sumait ainsi : "Ne sachant pas comment je fais [certaines choses avec mon esprit], il m'est impossible de programmer un ordinateur pour qu'il reproduise ce que je ne connais pas".
```

![](https://www.dilepix.com/hs-fs/hubfs/blog/schema-IA-machine-learning-deep-learning-Dilepix-1.png?width=600&name=schema-IA-machine-learning-deep-learning-Dilepix-1.png)

### Objectifs

‚úÖ Comprendre le fonctionnement et le vocabulaire de l'intelligence artificielle  
‚úÖ Comprendre pourquoi et comment utiliser le Machine Learning  
‚úÖ Conna√Ætre les diff√©rents types d'apprentissage (supervis√©, non supervis√©, par renforcement)  
‚úÖ Se familiariser avec les principales cat√©gories d'algorithmes (r√©gression, classification, clustering)  
‚úÖ Acqu√©rir les bases m√©thodologiques pour mener un projet de Machine Learning  
‚úÖ Conna√Ætre les fonctions de base de Scikit-learn

### Sommaire

### 1. Les r√©alisations possibles en Machine Learning

```alert-infos
L'id√©e du Machine Learning tourne autour du processus permettant aux machines d'apprendre √† partir des donn√©es pour faire des pr√©dictions, des classifications, ou d√©couvrir des patterns, sans √™tre explicitement programm√©es pour chaque t√¢che.
```

```alert-warning
**Avant de vous lancer dans le Machine Learning, vous devez** :    
1. Avoir des donn√©es en quantit√© suffisante
2. Avoir un objectif clair
```

### 2. Les types d'apprentissages et leurs utilit√©s

Il existe trois grandes cat√©gories d'apprentissage en Machine Learning :

#### Le Machine Learning supervis√©

```alert-infos
**Machine Learning supervis√©** :  
L'algorithme apprend √† partir d'un ensemble de donn√©es o√π chaque exemple est √©tiquet√© avec la bonne r√©ponse.

**Utilisations principales** :
- Pr√©dire une valeur num√©rique (r√©gression) : probabilit√©, consommation, √¢ge, chiffre d'affaires...
- Pr√©dire une classe (classification) : passager vivant/mort, type de fleur, genre de film, spam/non spam...
```

```alert
**Exemple concret** :  
Imaginez que vous souhaitez pr√©dire le prix d'une maison. Vous disposez d'un ensemble de donn√©es contenant des informations sur des maisons d√©j√† vendues (surface, nombre de chambres, localisation) et leur prix de vente. En utilisant l'apprentissage supervis√©, vous pouvez entra√Æner un mod√®le qui apprendra √† pr√©dire le prix d'une nouvelle maison en fonction de ses caract√©ristiques.
```

#### Le Machine Learning non supervis√©

```alert-infos
**Machine Learning non supervis√©** :  
Les mod√®les sont entra√Æn√©s sur des donn√©es non √©tiquet√©es, c'est-√†-dire sans r√©ponses ou cat√©gories pr√©d√©finies. L'objectif est de d√©couvrir des structures, des motifs ou des regroupements et cr√©er les √©tiquettes en cons√©quence.

**Utilisations principales** :
- Segmentation de client√®le (personas marketing)
- Analyse de s√©quences g√©n√©tiques
- Regroupement par caract√©ristiques min√©rales
```

```alert
**Exemple concret** :  
Supposons que vous dirigez une boutique en ligne et que vous souhaitez segmenter vos clients pour mieux cibler vos campagnes marketing. Avec l'apprentissage non supervis√©, vous pouvez regrouper automatiquement vos clients en fonction de leurs habitudes d'achat, sans avoir d√©fini pr√©alablement les groupes. Le mod√®le pourrait, par exemple, identifier naturellement les "acheteurs fr√©quents √† petit budget", les "acheteurs occasionnels √† gros budget", etc.
```

#### L'apprentissage par renforcement

```alert-warning
**Apprentissage par renforcement** :  
Permet √† un agent autonome d'apprendre par lui-m√™me en interagissant avec un environnement au travers d'une succession d'actions r√©compens√©es positivement ou n√©gativement.

Cette forme d'apprentissage est tr√®s co√ªteuse en puissance de calcul puisque l'environnement peut engendrer un nombre tr√®s grand de combinaisons d'actions possibles. On parle [d'explosion combinatoire](https://fr.wikipedia.org/wiki/Explosion_combinatoire).
```

```alert
**Exemple concret** :  
Un exemple fascinant est celui d'une IA entra√Æn√©e √† ex√©cuter une man≈ìuvre sp√©cifique afin de gagner une course de voiture dans le jeu vid√©o TrackMania. Au d√©but, l'IA ne sait pas conduire, mais √† force d'essais-erreurs et de r√©compenses (progresser dans la course), elle apprend non seulement √† conduire efficacement mais aussi √† exploiter les particularit√©s du jeu pour obtenir des performances surhumaines.

[AI learns to exploit a glitch in Trackmania](https://youtu.be/NUl6QikjR04)
```

![](https://i0.wp.com/deeplylearning.fr/wp-content/uploads/2018/09/type-of-learning.png?resize=781%2C558&ssl=1)

### 3. Les algorithmes classiques du Machine Learning

```alert-infos
**Scikit-learn** est une biblioth√®que Python open-source sp√©cialis√©e dans le Machine Learning. Elle fournit des impl√©mentations efficaces de nombreux algorithmes ainsi que des outils pour la pr√©paration des donn√©es, l'√©valuation des mod√®les et l'optimisation des param√®tres. C'est l'outil de r√©f√©rence pour les data scientists d√©butants et confirm√©s gr√¢ce √† son API coh√©rente et sa documentation de qualit√©.
```

#### 3.1 R√©gression

```alert-infos
**La r√©gression** est un type d'apprentissage supervis√© qui vise √† **pr√©dire une valeur num√©rique continue**. Par exemple, pr√©dire le prix d'une maison en fonction de sa superficie, du nombre de chambres, etc., ou pr√©dire la demande en √©lectricit√© en fonction de diff√©rents facteurs comme la temp√©rature.
```

```alert
**Quelques algorithmes de r√©gression courants dans Scikit-learn** :
- **R√©gression lin√©aire** : Mod√®le simple qui √©tablit une relation lin√©aire entre les variables d'entr√©e et la variable de sortie
- **R√©gression polynomiale** : Extension de la r√©gression lin√©aire qui permet de capturer des relations non lin√©aires
- **R√©gression Ridge et Lasso** : Variantes de la r√©gression lin√©aire avec des techniques de r√©gularisation pour √©viter le surajustement
```

```alert-warning
Les algorithmes de r√©gression et leurs sp√©cificit√©s math√©matiques seront abord√©s en profondeur dans les prochaines qu√™tes. Vous apprendrez notamment comment s√©lectionner le bon algorithme selon la nature de vos donn√©es et comment interpr√©ter les coefficients des mod√®les pour en tirer des insights m√©tier.
```

#### 3.2 Classification

```alert-infos
**La classification** est un autre type d'apprentissage supervis√© qui vise √† **classifier des donn√©es dans des cat√©gories pr√©d√©finies (√©tiquet√©es)**. Elle est utilis√©e pour identifier √† quelle classe appartient une nouvelle observation en fonction de ses caract√©ristiques. Par exemple, d√©terminer si un email est un spam ou non, ou identifier des images de chats et de chiens.
```

```alert
**Quelques algorithmes de classification courants dans Scikit-learn** :
- **K-Nearest Neighbors (KNN)** : Classe une nouvelle observation selon les classes des k observations les plus proches
- **R√©gression logistique** : Malgr√© son nom, c'est un algorithme de classification qui estime la probabilit√© d'appartenance √† une classe
- **Arbres de d√©cision** : Mod√®le qui prend des d√©cisions bas√©es sur une s√©rie de questions
- **Random Forest** : Ensemble d'arbres de d√©cision dont les r√©sultats sont combin√©s
- **Naive Bayes** : Algorithme probabiliste bas√© sur le th√©or√®me de Bayes
- **Support Vector Machines (SVM)** : Cherche √† trouver un hyperplan qui s√©pare au mieux les classes
```

```alert-warning
Les algorithmes de classification et leurs cas d'usage seront d√©taill√©s dans les prochaines qu√™tes. Vous y d√©couvrirez comment g√©rer des probl√®mes de classification multiclasse, comment traiter les d√©s√©quilibres de classes, et comment utiliser les probabilit√©s de pr√©diction pour prendre des d√©cisions m√©tier plus nuanc√©es.
```

#### 3.3 Clustering

```alert-infos
**Le clustering** est un type d'apprentissage non supervis√© qui vise √† **regrouper des donn√©es en fonction de leurs similarit√©s**. Il est utilis√© pour automatiquement identifier des structures r√©currentes (patterns) dans les donn√©es sans avoir √† d√©finir de classes au pr√©alable. Par exemple, segmenter des clients en fonction de leurs habitudes d'achat, ou identifier des groupes de g√®nes qui s'expriment de mani√®re similaire.
```

```alert
**Quelques algorithmes de clustering courants dans Scikit-learn** :
- **K-means** : Divise les donn√©es en k groupes en minimisant la distance entre les points et le centre de leur cluster
- **Hierarchical Clustering** : Construit une hi√©rarchie de clusters, soit en regroupant progressivement les points (approche ascendante), soit en divisant r√©cursivement l'ensemble (approche descendante)
- **DBSCAN** : Identifie des clusters de densit√© variable et peut d√©tecter des outliers
- **Spectral Clustering** : Utilise les propri√©t√©s du spectre de la matrice de similarit√© pour r√©duire la dimensionnalit√© avant le clustering
```

```alert-warning
Les techniques de clustering et leurs applications m√©tier seront approfondies dans les prochaines qu√™tes. Vous apprendrez notamment comment d√©terminer le nombre optimal de clusters, comment interpr√©ter les r√©sultats de clustering, et comment utiliser ces insights pour orienter vos strat√©gies marketing ou vos analyses exploratoires.
```

```alert-success
**Aide au choix d'un algorithme** :  
Scikit-learn propose un "cheat sheet" tr√®s pratique pour vous aider √† choisir l'algorithme le plus adapt√© √† votre probl√®me en fonction de la taille de vos donn√©es, de leur nature et de votre objectif.
```

![](https://scikit-learn.org/1.3/_static/ml_map.png)

### 4. Fonctionnement et m√©thodologie

```alert-infos
Nous pouvons r√©sumer le processus commun √† tous ces algorithmes de la mani√®re suivante. Cette m√©thodologie s'applique que vous utilisiez Scikit-learn ou toute autre biblioth√®que de Machine Learning, et constitue un cadre essentiel pour structurer vos projets d'analyse pr√©dictive.
```

#### 4.1 D√©finition du besoin

```alert-warning
Avant de commencer, posez-vous les bonnes questions :
- Quel est l'objectif de mon projet ?
- Souhait√©-je pr√©dire une valeur num√©rique ?
- Cherch√©-je √† classer des observations dans des cat√©gories ?
- Ai-je besoin de regrouper des observations similaires ?
```

#### 4.2 Exploration des donn√©es

```alert-infos
Cette √©tape consiste √† utiliser des m√©thodes de statistiques descriptives, des visualisations et des outils d'exploration comme Numpy et Pandas, dans le but de mieux comprendre ce qu'il vous sera possible de faire avec les donn√©es actuelles.

La quantit√© mais aussi la qualit√© des donn√©es sont importantes pour que le mod√®le apprenne correctement.
```

```alert
**Actions typiques lors de l'exploration** :
- Visualiser la distribution des variables
- Identifier les corr√©lations entre les variables
- D√©tecter les valeurs aberrantes et manquantes
- Analyser les tendances et patterns visuels
```

#### 4.3 Pr√©paration des donn√©es

```alert-warning
Nous avons fait un √©tat des lieux lors de l'exploration, place au nettoyage √† travers divers traitements relatifs aux donn√©es :

- **Typage de donn√©es** : Conversion des variables au type appropri√© (int, float, categorical, etc.)
- **Gestion des valeurs manquantes** : Imputation ou suppression selon le contexte
- **Standardisation** : Mise √† l'√©chelle des variables pour qu'elles aient une moyenne de 0 et un √©cart-type de 1
- **Normalisation** : Mise √† l'√©chelle des variables pour qu'elles soient comprises entre 0 et 1
- **Encodage** : Transformation des variables cat√©gorielles en variables num√©riques
```

```alert-error
**Attention** :  
Cette √©tape est g√©n√©ralement consid√©r√©e comme la plus longue (et la plus fastidieuse üòÆ‚Äçüí®) d'un projet de data science, pouvant repr√©senter jusqu'√† 80% du temps total. Ne la n√©gligez pas, car la qualit√© de vos donn√©es d√©termine directement la qualit√© de vos r√©sultats !
```

```alert-success
Le but final de cette √©tape est de d√©finir quelles "features" (colonnes) seront les caract√©ristiques d√©terminantes pour notre objectif. Ces colonnes s√©lectionn√©es seront, par convention, notre X.

Il sera peut-√™tre n√©cessaire de *cr√©er de nouvelles colonnes* (feature engineering) √† partir de features existantes en fonction des besoins.
```

```alert-info
**Avec un algorithme supervis√©**, nous d√©finirons √©galement une cible √† pr√©dire, par convention notre "y".

Nous diviserons ensuite nos donn√©es en un jeu d'entra√Ænement, sur lequel notre algorithme apprendra, et un jeu de "test" qui servira √† √©valuer la diff√©rence entre la pr√©diction et la r√©alit√© => `train_test_split()`
```

#### 4.4 Choix & Entra√Ænement du mod√®le

```alert-infos
La cr√©ation du mod√®le sera l'√©tape o√π l'on va d√©cider, en fonction des √©tapes pr√©c√©dentes, quels algorithmes seront les plus adapt√©s √† nos donn√©es pour atteindre l'objectif d√©fini.

Nous proc√®derons ensuite √† l'entra√Ænement de l'algorithme choisi, en d√©finissant certains param√®tres, relatifs √† l'algorithme choisi (tous les algorithmes n'ont pas les m√™mes param√®tres).
```

```alert
**En pratique avec Scikit-learn** :
1. Instancier le mod√®le : `model = Algorithm(param1=value1, param2=value2)`
   - `Algorithm` est remplac√© par l'algorithme choisi (ex: `LinearRegression`, `RandomForestClassifier`, etc.)
   - `param1`, `param2` sont des hyperparam√®tres sp√©cifiques √† l'algorithme (ex: `n_estimators=100` pour Random Forest)

2. Entra√Æner le mod√®le : `model.fit(X_train, y_train)`
   - `X_train` : jeu de donn√©es d'entra√Ænement (features) obtenu apr√®s `train_test_split()`
   - `y_train` : cibles d'entra√Ænement correspondantes (valeurs √† pr√©dire)

3. Faire des pr√©dictions : `y_pred = model.predict(X_test)`
   - `X_test` : jeu de donn√©es de test (features) obtenu apr√®s `train_test_split()`
   - `y_pred` : pr√©dictions g√©n√©r√©es par le mod√®le √† comparer avec les vraies valeurs `y_test`

**Exemple concret** :
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import pandas as pd

# Chargement des donn√©es
data = pd.read_csv('house_prices.csv')

# D√©finition des features (X) et de la cible (y)
X = data[['surface', 'bedrooms', 'bathrooms', 'age']]  # Variables explicatives
y = data['price']  # Variable √† pr√©dire

# Division en jeux d'entra√Ænement et de test (75% entra√Ænement, 25% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Instanciation et entra√Ænement du mod√®le
model = LinearRegression()
model.fit(X_train, y_train)

# Pr√©dictions
y_pred = model.predict(X_test)
```

```alert-warning
Nous explorerons de fa√ßon beaucoup plus approfondie ces concepts dans les prochaines qu√™tes. Vous apprendrez notamment comment choisir les bons hyperparam√®tres, comment manipuler diff√©rents types de donn√©es, et comment √©valuer pr√©cis√©ment vos mod√®les.
```
#### 4.5 Interpr√©tation des r√©sultats & √âvaluation du mod√®le

```alert-infos
Dans cette √©tape, on mesure √† quel point le mod√®le arrive √† pr√©dire correctement les choses de diff√©rentes mani√®res gr√¢ce √† des m√©triques d'√©valuation.

Ces m√©triques sont sp√©cifiques en fonction du contexte de r√©gression ou de classification. On mesure ainsi sa capacit√© de g√©n√©ralisation !
```

```alert-warning
**La g√©n√©ralisation garantit que le mod√®le ne se contente pas de m√©moriser les donn√©es d'entra√Ænement, mais qu'il apprend des patterns sous-jacents qui lui permettent de faire des pr√©dictions pr√©cises sur de nouvelles donn√©es.**
```

```alert
**M√©triques courantes en r√©gression** :
- MAE (Mean Absolute Error) : Erreur absolue moyenne
- MSE (Mean Squared Error) : Erreur quadratique moyenne
- RMSE (Root Mean Squared Error) : Racine carr√©e de l'erreur quadratique moyenne
- R¬≤ (coefficient de d√©termination) : Proportion de la variance expliqu√©e par le mod√®le

**M√©triques courantes en classification** :
- Accuracy (pr√©cision) : Proportion de pr√©dictions correctes
- Precision : Proportion des pr√©dictions positives qui sont r√©ellement positives
- Recall (rappel) : Proportion des cas positifs r√©els qui sont correctement pr√©dits
- F1-score : Moyenne harmonique de la pr√©cision et du rappel
- Matrice de confusion : Tableau qui montre les pr√©dictions correctes et incorrectes pour chaque classe
```

```alert-error
L'interpr√©tation correcte des m√©triques d'√©valuation est cruciale pour juger de la qualit√© de votre mod√®le. 

Dans les prochaines qu√™tes, vous apprendrez √† choisir les m√©triques les plus pertinentes selon votre contexte m√©tier, √† interpr√©ter les diff√©rentes m√©triques et √† d√©tecter les probl√®mes classiques comme le sous-apprentissage (underfitting) ou le sur-apprentissage (overfitting).
```

#### 4.6 Optimisation des param√®tres

```alert-success
Les r√©sultats obtenus avec ces algorithmes de Machine Learning peuvent s'am√©liorer gr√¢ce √† l'optimisation des param√®tres. Le but est d'arriver √† minimiser l'√©cart entre la pr√©diction et les valeurs r√©elles.
```

```alert-infos
**Techniques d'optimisation courantes** :
- **Grid Search** : Teste toutes les combinaisons possibles de param√®tres sp√©cifi√©s
- **Random Search** : Teste al√©atoirement des combinaisons de param√®tres dans un espace d√©fini
- **Cross-validation** : Divise les donn√©es en plusieurs sous-ensembles pour valider la robustesse du mod√®le
```

#### NOTE BENE

```alert-success
Ces √©tapes nous permettent de cr√©er et optimiser un mod√®le de pr√©diction.

Celui qui utilise ce genre d'algorithme (ou mod√®le) n'est pas un concepteur mais **un entra√Æneur d'algorithmes**.

On vous inclut ce sch√©ma synth√©tique qui r√©sume les √©tapes les plus importantes dans le **Machine Learning**.
```
![](https://www.dilepix.com/hs-fs/hubfs/blog/schema-IA-machine-learning-deep-learning-Dilepix-1.png?width=600&name=schema-IA-machine-learning-deep-learning-Dilepix-1.png)


### 5. Quiz de connaissances

```quiz
true|||true|||true
# Qu'est-ce que le Machine Learning ?
[x] Une branche de l'intelligence artificielle qui permet aux ordinateurs d'apprendre sans √™tre explicitement programm√©s
[] Un langage de programmation sp√©cialis√© dans le traitement des donn√©es
[] Une m√©thode pour programmer des ordinateurs de mani√®re plus efficace

# Quel type d'apprentissage utilise des donn√©es √©tiquet√©es ?
[x] L'apprentissage supervis√©
[] L'apprentissage non supervis√©
[] L'apprentissage par renforcement

# Dans un contexte de Machine Learning, que repr√©sente g√©n√©ralement "X" ?
[x] Les features (caract√©ristiques) utilis√©es pour faire des pr√©dictions
[] La cible √† pr√©dire
[] Le nombre d'it√©rations d'entra√Ænement

# Quelle technique est utilis√©e pour diviser les donn√©es en jeu d'entra√Ænement et jeu de test ?
[x] train_test_split()
[] K-means
[] Random Forest

# Quelle m√©trique d'√©valuation est particuli√®rement adapt√©e aux probl√®mes de r√©gression ?
[x] RMSE (Root Mean Squared Error)
[] Accuracy
[] F1-score

# Quelle √©tape du processus de Machine Learning est g√©n√©ralement consid√©r√©e comme la plus longue ?
[x] La pr√©paration des donn√©es
[] L'entra√Ænement du mod√®le
[] L'optimisation des param√®tres

# Quel algorithme est le plus adapt√© pour regrouper des clients en segments sans cat√©gories pr√©d√©finies ?
[] R√©gression lin√©aire
[] R√©gression logistique
[x] K-means

# Lequel des algorithmes suivants est un exemple d'apprentissage supervis√© ?
[x] Random Forest
[] DBSCAN
[] K-means

# Qu'est-ce que l'overfitting (sur-apprentissage) ?
[x] Le mod√®le apprend trop bien les donn√©es d'entra√Ænement et perd en capacit√© de g√©n√©ralisation
[] Le mod√®le n'arrive pas √† capturer la complexit√© des donn√©es
[] Le mod√®le requiert trop de puissance de calcul

# Quel type d'algorithme utiliseriez-vous pour pr√©dire si un email est un spam ou non ?
[] Algorithme de r√©gression
[x] Algorithme de classification
[] Algorithme de clustering

# Dans l'apprentissage par renforcement, qu'est-ce qu'une r√©compense ?
[x] Un signal qui indique si l'action de l'agent est bonne ou mauvaise
[] Le temps n√©cessaire pour que l'agent accomplisse sa t√¢che
[] Le nombre d'erreurs commises par l'agent

# √Ä quoi sert la validation crois√©e (cross-validation) ?
[x] √Ä √©valuer la performance d'un mod√®le sur diff√©rents sous-ensembles de donn√©es
[] √Ä nettoyer les donn√©es avant l'entra√Ænement
[] √Ä visualiser les donn√©es avant la mod√©lisation

# Qu'est-ce qu'une matrice de confusion ?
[x] Un tableau qui montre les pr√©dictions correctes et incorrectes pour chaque classe
[] Une visualisation des corr√©lations entre diff√©rentes variables
[] Une technique pour r√©duire la dimensionnalit√© des donn√©es

# Quelle technique est utilis√©e pour trouver les meilleurs param√®tres d'un mod√®le ?
[] Data cleaning
[x] Grid Search ou Random Search
[] Feature engineering

# Quel est l'objectif de la standardisation des donn√©es ?
[x] Transformer les variables pour qu'elles aient une moyenne de 0 et un √©cart-type de 1
[] Convertir toutes les variables en variables cat√©gorielles
[] Supprimer les valeurs aberrantes

# Qu'est-ce que le coefficient de d√©termination (R¬≤) mesure ?
[x] La proportion de la variance de la variable cible qui est expliqu√©e par le mod√®le
[] Le nombre d'erreurs commises par le mod√®le
[] Le temps n√©cessaire pour entra√Æner le mod√®le
```

### 6. Conclusion et ressources

```alert-success
Ces √©tapes nous permettent de cr√©er et optimiser un mod√®le de pr√©diction.
Celui qui utilise ce genre d'algorithme (ou mod√®le) n'est pas un concepteur mais **un entra√Æneur d'algorithmes**.

Dans les prochaines qu√™tes, vous mettrez en pratique ces concepts √† travers des projets concrets et vous approfondirez vos connaissances sur chaque type d'algorithme.
```

```alert-info
**Ressources pour approfondir** :
- [Wikipedia - Machine Learning](https://en.wikipedia.org/wiki/machine_learning)
- [Mr. Mint - Tutoriels sur le ML](https://mrmint.fr/)
- [Introduction au machine learning avec Python](https://brightcape.co/introduction-au-machine-learning-avec-python/)
- [Documentation officielle de Scikit-learn](https://scikit-learn.org/stable/documentation.html)
```
